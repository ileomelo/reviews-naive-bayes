{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780245e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Caminho para o arquivo CSV\n",
    "file_path = \"user_courses_review_09_2023.csv\"\n",
    "\n",
    "# Lista para armazenar as linhas de dados\n",
    "data_list = []\n",
    "\n",
    "# Numero de colunas esperado por cada linha\n",
    "EXPECTED_COLUMNS = 4  # Troque esse numero conforme necessário\n",
    "\n",
    "# Abrir o arquivo CSV e ler linha por linha\n",
    "with open(file_path, \"r\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Opcional: Ler o cabeçalho se existir\n",
    "    header = next(reader)\n",
    "\n",
    "    # Ler cada linha\n",
    "    for row in reader:\n",
    "        # Verificar se a linha tem o número esperado de colunas\n",
    "        if len(row) == EXPECTED_COLUMNS:\n",
    "            data_list.append(row)\n",
    "        else:\n",
    "            print(f\"Linha ignorada: {reader.line_num}: {row}\")\n",
    "\n",
    "# Converter a lista de dados em um DataFrame do Pandas\n",
    "df = pd.DataFrame(data_list, columns=header)\n",
    "\n",
    "# Mostrar as primeiras linhas do DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4479d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checando os data types das colunas\n",
    "data_types = df.dtypes\n",
    "\n",
    "print(data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48dfc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter 'review_rating' para numérico\n",
    "if df[\"review_rating\"].dtype == \"object\":\n",
    "    # Força a a conversão para numérico, tratando erros como NaN\n",
    "    df[\"review_rating\"] = pd.to_numeric(df[\"review_rating\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7d4b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se a conversão foi bem-sucedida e valores ausentes\n",
    "new_data_types = df.dtypes\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "print(new_data_types)\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4adb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Summary estatistica para review_rating\n",
    "review_rating_summary = df[\"review_rating\"].describe()\n",
    "print(review_rating_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02bb42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico de distribuição de review_rating\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(\n",
    "    df[\"review_rating\"].dropna(),\n",
    "    bins=range(1, 7),\n",
    "    align=\"left\",\n",
    "    rwidth=0.9,\n",
    "    color=\"skyblue\",\n",
    "    edgecolor=\"gray\",\n",
    ")\n",
    "plt.title(\"Distribuição de Avaliações dos Cursos\")\n",
    "plt.xlabel(\"Avaliação\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "plt.xticks(range(1, 6))\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fc908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover linhas com dados ausentes\n",
    "df_cleaned = df.dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1434dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkando o novo shape do DataFrame\n",
    "print(\n",
    "    f\"Shape do DataFrame após remoção de linhas com dados ausentes: {df_cleaned.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef9cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para analise de correlação, primeiro precisamos adicionar uma nova coluna com o tamanho dos comentarios\n",
    "df_cleaned[\"comment_length\"] = df_cleaned[\"review_comment\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a987a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular a correlação entre review_rating e comment_length\n",
    "correlation = df_cleaned[[\"review_rating\", \"comment_length\"]].corr()\n",
    "\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c41e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define regex patterns para procurar palavras-chave\n",
    "patterns = {\n",
    "    \"positive\": re.compile(\n",
    "        r\"\\b(good|great|excellent|amazing|love|enjoy|awesome|best|fantastic)\\b\",\n",
    "        re.IGNORECASE,\n",
    "    ),\n",
    "    \"negative\": re.compile(\n",
    "        r\"\\b(bad|terrible|awful|hate|dislike|poor|worst|disappoint)\\b\", re.IGNORECASE\n",
    "    ),\n",
    "    \"question\": re.compile(r\"\\?\"),\n",
    "    \"exclamation\": re.compile(r\"\\!\"),\n",
    "    \"capitalized\": re.compile(\n",
    "        r\"\\b[A-Z]{2,}\\b\"\n",
    "    ),  # palavras com 2 ou mais letras maiúsculas\n",
    "}\n",
    "\n",
    "# Inicializa um dicionário para armazenar as contagens para cada padrão\n",
    "pattern_counts = {key: 0 for key in patterns}\n",
    "\n",
    "# Scan cada comentário e contar as ocorrências de cada padrão\n",
    "for comment in df_cleaned[\"review_comment\"]:\n",
    "    for key, pattern in patterns.items():\n",
    "        if re.search(pattern, comment):\n",
    "            pattern_counts[key] += 1\n",
    "\n",
    "pattern_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ba6ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import string\n",
    "\n",
    "\n",
    "# Função para pré-processar os comentários\n",
    "def preprocess_text(text):\n",
    "    # Remove pontuação e converte para minúsculas\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n",
    "    return text\n",
    "\n",
    "\n",
    "# Aplicar a função de pré-processamento\n",
    "df_cleaned[\"review_comment\"] = df_cleaned[\"review_comment\"].apply(preprocess_text)\n",
    "\n",
    "# Dividir os dados em conjunto de treino e teste\n",
    "X = df_cleaned.loc[:, \"review_comment\"]\n",
    "Y = df_cleaned.loc[:, \"review_comment\"]\n",
    "\n",
    "# Dividir os dados entre treino e teste\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfabc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar a TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Inicializar o modelo Naive Bayes Multinomial\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Criar uma pipeline que combina o vetorizar e o modelo\n",
    "pipeline = make_pipeline(vectorizer, model)\n",
    "\n",
    "# Treinar o modelo\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "Y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calcular e exibir o relatório de classificação\n",
    "report = classification_report(Y_test, Y_pred)\n",
    "\n",
    "# Exibir a matriz de confusão\n",
    "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "report, conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b5d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separar as classes minoritárias e majoritárias\n",
    "df_majority = df_cleaned[df_cleaned[\"review_rating\"] == 5]\n",
    "df_minority = df_cleaned[df_cleaned[\"review_rating\"] < 5]\n",
    "\n",
    "# Upsample a classe minoritária\n",
    "df_minority_upsampled = resample(\n",
    "    df_minority,\n",
    "    replace=True,  # Amostragem com reposição\n",
    "    n_samples=len(\n",
    "        df_majority\n",
    "    ),  # Para igualar o número de amostras da classe majoritária\n",
    "    random_state=42,\n",
    ")  # Para reprodutibilidade\n",
    "\n",
    "# Combinar a classe majoritária com a classe minoritária upsampled\n",
    "df_balanced = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Verificar o novo balanceamento das classes\n",
    "print(df_balanced[\"review_rating\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e693596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar os dados balanceados em X e Y\n",
    "X_balanced = df_balanced[\"review_comment\"]\n",
    "Y_balanced = df_balanced[\"review_rating\"]\n",
    "\n",
    "# Dividir os dados balanceados entre treino e teste\n",
    "X_train_balanced, X_test_balanced, Y_train_balanced, Y_test_balanced = train_test_split(\n",
    "    X_balanced, Y_balanced, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Treinar o modelo novamente com os dados balanceados\n",
    "pipeline_upsampled = make_pipeline(vectorizer, model)\n",
    "pipeline_upsampled.fit(X_train_balanced, Y_train_balanced)\n",
    "\n",
    "# Fazer previsões no conjunto de teste balanceado\n",
    "Y_pred_balanced = pipeline_upsampled.predict(X_test_balanced)\n",
    "\n",
    "# Calcular e exibir o relatório de classificação para os dados balanceados\n",
    "report_balanced = classification_report(Y_test_balanced, Y_pred_balanced)\n",
    "\n",
    "# Calcular a matriz de confusão para os dados balanceados\n",
    "conf_matrix_balanced = confusion_matrix(Y_test_balanced, Y_pred_balanced)\n",
    "\n",
    "report_balanced, conf_matrix_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a524bf0c",
   "metadata": {},
   "source": [
    "### Classification Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f9135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a função para converter o 'rating' em 'good' ou 'bad'\n",
    "def binary_rating(rating):\n",
    "    if rating >= 4:\n",
    "        return \"good\"\n",
    "    else:\n",
    "        return \"bad\"\n",
    "\n",
    "\n",
    "# Aplica a função de conversão ao DataFrame na coluna 'review_rating'\n",
    "binary_data = df_cleaned.copy()\n",
    "binary_data[\"review_rating\"] = binary_data[\"review_rating\"].apply(binary_rating)\n",
    "\n",
    "# Separar os dados binários em X e Y\n",
    "X_binary = binary_data[\"review_comment\"]\n",
    "Y_binary = binary_data[\"review_rating\"]\n",
    "\n",
    "# Dividir os dados binários entre treino e teste\n",
    "X_train_binary, X_test_binary, Y_train_binary, Y_test_binary = train_test_split(\n",
    "    X_binary, Y_binary, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Treinar o modelo novamente com os dados binários\n",
    "pipeline_binary = make_pipeline(vectorizer, model)\n",
    "pipeline_binary.fit(X_train_binary, Y_train_binary)\n",
    "\n",
    "# Fazer previsões no conjunto de teste binário\n",
    "Y_pred_binary = pipeline_binary.predict(X_test_binary)\n",
    "\n",
    "# Calcular e exibir o relatório de classificação para os dados binários\n",
    "report_binary = classification_report(Y_test_binary, Y_pred_binary, output_dict=True)\n",
    "\n",
    "# Calcular a matriz de confusão para os dados binários\n",
    "conf_matrix_binary = confusion_matrix(Y_test_binary, Y_pred_binary)\n",
    "\n",
    "# Cnoverte o reporte de classificação em um DataFrame\n",
    "report_binary_df = pd.DataFrame(report_binary).transpose()\n",
    "\n",
    "report_binary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8f31aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar a matriz de confusão\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    conf_matrix_binary,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"bad\", \"good\"],\n",
    "    yticklabels=[\"bad\", \"good\"],\n",
    ")\n",
    "plt.title(\"Matriz de Confusão - Classificação Binária\")\n",
    "plt.xlabel(\"Previsão\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c611f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar os dados majoritários e minoritários\n",
    "df_majority = binary_data[binary_data[\"review_rating\"] == \"good\"]\n",
    "df_minority = binary_data[binary_data[\"review_rating\"] == \"bad\"]\n",
    "\n",
    "# Oversample a classe minoritária\n",
    "df_minority_upsampled_binary = resample(\n",
    "    df_minority,\n",
    "    replace=True,  # Amostragem com reposição\n",
    "    n_samples=len(\n",
    "        df_majority\n",
    "    ),  # Para igualar o número de amostras da classe majoritária\n",
    "    random_state=42,\n",
    ")  # Para reprodutibilidade\n",
    "\n",
    "# Combinar a classe majoritária com a classe minoritária upsampled\n",
    "df_balanced_binary = pd.concat([df_majority, df_minority_upsampled_binary])\n",
    "\n",
    "# Verificar o novo balanceamento das classes\n",
    "print(df_balanced_binary[\"review_rating\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18f58de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar os dados upsampled binary data em features(X) e labels(Y)\n",
    "X_upsampled_binary = df_balanced_binary[\"review_comment\"]\n",
    "Y_upsampled_binary = df_balanced_binary[\"review_rating\"]\n",
    "\n",
    "# Dividir os dados balanceados entre treino e teste\n",
    "(\n",
    "    X_train_upsampled_binary,\n",
    "    X_test_upsampled_binary,\n",
    "    Y_train_upsampled_binary,\n",
    "    Y_test_upsampled_binary,\n",
    ") = train_test_split(\n",
    "    X_upsampled_binary, Y_upsampled_binary, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Treinar o modelo novamente com os dados balanceados binários\n",
    "pipeline_upsampled_binary = make_pipeline(vectorizer, model)\n",
    "pipeline_upsampled_binary.fit(X_train_upsampled_binary, Y_train_upsampled_binary)\n",
    "\n",
    "# Fazer previsões no conjunto de teste balanceado binário\n",
    "Y_pred_upsampled_binary = pipeline_upsampled_binary.predict(X_test_upsampled_binary)\n",
    "\n",
    "# Calcular e exibir o relatório de classificação para os dados balanceados binários\n",
    "report_upsampled_binary = classification_report(\n",
    "    Y_test_upsampled_binary, Y_pred_upsampled_binary, output_dict=True\n",
    ")\n",
    "\n",
    "# Calcular a matriz de confusão para os dados balanceados binários\n",
    "conf_matrix_upsampled_binary = confusion_matrix(\n",
    "    Y_test_upsampled_binary, Y_pred_upsampled_binary\n",
    ")\n",
    "\n",
    "# Converte o reporte de classificação em um DataFrame\n",
    "report_upsampled_binary_df = pd.DataFrame(report_upsampled_binary).transpose()\n",
    "\n",
    "report_upsampled_binary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d1936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer o plot da matriz de confusão como heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    conf_matrix_upsampled_binary,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"bad\", \"good\"],\n",
    "    yticklabels=[\"bad\", \"good\"],\n",
    ")\n",
    "plt.title(\"Matriz de Confusão - Classificação Binária Balanceada\")\n",
    "plt.xlabel(\"Previsão\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b1eeed",
   "metadata": {},
   "source": [
    "### Teste Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3bcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o arquivo de teste\n",
    "test_file = pd.read_csv(\n",
    "    \"user_courses_review_test.csv\",\n",
    "    encoding=\"utf-8\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8e7b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover linhas com dados ausentes em 'review_comment' ou 'review_rating'\n",
    "test_set_clean = test_file.dropna(subset=[\"review_comment\", \"review_rating\"]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c01f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter 'review_rating' para numérico\n",
    "test_set_clean[\"review_rating\"] = pd.to_numeric(\n",
    "    test_set_clean[\"review_rating\"], errors=\"coerce\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f95275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checar se há NaN após a conversão e remover essas linhas\n",
    "test_set_clean = test_set_clean.dropna(subset=[\"review_rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ae1801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para categorizar as reviews\n",
    "def binary_rating(rating):\n",
    "    return \"good\" if rating >= 4.0 else \"bad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ab0434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpar review_comment\n",
    "test_set_clean[\"review_comment\"] = test_set_clean[\"review_comment\"].apply(\n",
    "    preprocess_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b0dbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar 'binary_rating' para converter 'review_rating' em 'good' ou 'bad'\n",
    "test_set_clean[\"review_rating\"] = test_set_clean[\"review_rating\"].apply(binary_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f230ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ter certeza que o processamento foi feito corretamente\n",
    "test_set_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar as features e labels do modelo limpo, para teste\n",
    "X_test_clean = test_set_clean[\"review_comment\"]\n",
    "Y_test_clean = test_set_clean[\"review_rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a2d88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previsões no conjunto de teste limpo\n",
    "Y_test_pred_clean = pipeline_upsampled_binary.predict(X_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aea8635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular a classificação do relatório para o conjunto de teste limpo\n",
    "report_test_clean = classification_report(\n",
    "    Y_test_clean, Y_test_pred_clean, output_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4188124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular a matriz de confusão para o conjunto de teste limpo\n",
    "conf_matrix_test_clean = confusion_matrix(Y_test_clean, Y_test_pred_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78693a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a classificação do relatório em um DataFrame\n",
    "report_test_clean_df = pd.DataFrame(report_test_clean).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab29f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar a matriz de confusão do conjunto de teste limpo em heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    conf_matrix_test_clean,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"bad\", \"good\"],\n",
    "    yticklabels=[\"bad\", \"good\"],\n",
    ")\n",
    "plt.title(\"Matriz de Confusão - Conjunto de Teste Limpo\")\n",
    "plt.xlabel(\"Previsão\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee99a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report_test_clean_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
